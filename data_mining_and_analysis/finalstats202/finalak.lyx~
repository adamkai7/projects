#LyX 2.3 created this file. For more info see http://www.lyx.org/
\lyxformat 544
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass amsart
\use_default_options true
\begin_modules
theorems-ams
eqs-within-sections
figs-within-sections
\end_modules
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman "default" "default"
\font_sans "default" "default"
\font_typewriter "default" "default"
\font_math "auto" "auto"
\font_default_family rmdefault
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\use_microtype false
\use_dash_ligatures true
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize 12
\spacing single
\use_hyperref false
\papersize default
\use_geometry true
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 1
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine basic
\cite_engine_type default
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 1
\use_minted 0
\index Index
\shortcut idx
\color #008000
\end_index
\leftmargin 1in
\topmargin 1in
\rightmargin 1in
\bottommargin 1in
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\is_math_indent 0
\math_numbering_side default
\quotes_style english
\dynamic_quotes 0
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Title
STATS 202: Data Mining and Analysis Final
\end_layout

\begin_layout Section*
Instructor: Linh Tran 
\end_layout

\begin_layout Section*
Final Project
\end_layout

\begin_layout Section*
Due Date: August 2, 2023
\end_layout

\begin_layout Section*
Stanford University 
\end_layout

\begin_layout Section*
Adam Kainikara 
\end_layout

\begin_layout Part*
Kaggle Reference
\end_layout

\begin_layout Verbatim
Team Name: Adam Kainikara.
\end_layout

\begin_layout Verbatim
Work done by Adam Kainikara.
\end_layout

\begin_layout Part
Treatment Effect
\end_layout

\begin_layout Standard
Using Python I loaded the data from all available CSV sets.
 Created a function called find_patients which took the input of the loaded
 data and returned every unique patient id.
 After collecting every patient id, I created a blank dictionary.
 The dictionary would have the patient id as the key.
 For values, I stored all the associated values of each patient in an array.
 For patients that had one or more visit days, the information would also
 be stored.
 The following is an example of how I stored the data.
\end_layout

\begin_layout Standard
dtype=[('study', '<U10'), (country, '<U10'), ('txgroup', '<U10'), ('assesmentid'
, '<f8'), ('patientid', '<f8'), ('visitday', '<i4'), ('xvalues', '<f8',
 (30,)), ('panss', '<f8'), ('leadstatus', '<U10')]), 30951.0: array([('"C"',
 '"China"', '"Control"', 304958., 30951., 0, [4., 3., 2., 1., 3., 4., 2., 4., 5., 4.,
 5., 4., 5., 3., 1., 2., 1., 1., 4., 1., 4., 4., 3., 3., 4., 6., 3., 1., 5., 2.], 94., '"Assign
 to'), ('"C"', '"China"', '"Control"', 301327., 30951., 7, [4., 3., 2., 1., 2.,
 4., 2., 4., 5., 4., 5., 4., 5., 3., 1., 1., 1., 1., 4., 1., 4., 4., 3., 3., 4., 6., 3., 1., 4.,
 2.], 91., '"Assign to'), ('"C"', '"China"', '"Control"', 303725., 30951., 14,
 [4., 3., 2., 1., 1., 4., 2., 4., 5., 4., 5., 4., 5., 3., 1., 1., 1., 1., 4., 2., 4., 4., 3., 3.,
 4., 6., 3., 1., 4., 2.], 91., '"Passed"'), ('"C"', '"China"', '"Control"', 304954.,
 30951., 42, [4., 3., 4., 1., 1., 4., 2., 4., 5., 5., 5., 4., 5., 3., 1., 2., 1., 1., 4., 3.,
 4., 4., 3., 3., 4., 6., 3., 2., 5., 2.], 98., '"Passed"'), ('"C"', '"China"', '"Control"',
 307645., 30951., 70, [4., 2., 2., 3., 1., 4., 3., 5., 5., 6., 6., 5., 5., 4., 2., 3., 1.,
 1., 4., 3., 5., 5., 3., 3., 4., 6., 3., 3., 5., 2.], 108., '"Passed"')
\end_layout

\begin_layout Standard
After this was done, patients were further filtered into a control group
 and a treatment group.
 In addition, patients with fewer than one visit day were removed.
 Below is a graph of treatment and control groups.
 The X axis is visit day and Y axis is PANSS score.
 To reduce clutter on the graph, only Study E is shown.
 
\end_layout

\begin_layout Standard
\noindent
\align center
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename img/question1treat.png
	lyxscale 50
	width 85page%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Treatment Group: Study E
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\noindent
\align center
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename img/question1.png
	lyxscale 50
	width 85page%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Control Group: Study E
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
After, I calculated the difference between each patient's final PANNS score
 and their initial score.
 The distribution of the difference in scores can be seen bellow.
\end_layout

\begin_layout Standard
\noindent
\align center
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename img/difdistcont.png
	lyxscale 50
	width 85page%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Differences in Control Group
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\noindent
\align center
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename img/difdisttreatment.png
	lyxscale 50
	width 85page%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Differences in Treatment Group
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
The distribution of difference scores in the control group is somewhat normal
 where as the distribution of difference of scores in the treatment group
 is skewed.The mean difference of patients in the control group was -16.13
 with a standard deviation of 19.40.
 That is on average, patients in the control group on average saw their
 PANSS score decrease by 16 at the end of the study.
 The mean difference of patients in the treatment group was -15.98 with a
 standard deviation of 19.24.
\end_layout

\begin_layout Standard
To see if the treatment had any affect, a t test will be conducted where
 
\begin_inset Formula $H_{0}$
\end_inset

 is there is no significant difference in the mean change in score between
 the treatment and control groups and 
\begin_inset Formula $H_{a}$
\end_inset

 is there is a significant difference in the mean change in score between
 the treatment and control groups.
 Patients were randomly assigned to either treatment or control.
 With 
\begin_inset Formula $\alpha=0.05$
\end_inset

 a test statistic of 0.2105 and 2945 degress of freedom.
 The p value is 0.416.
 The result is not significant.
 The treatment affect does not make a significant impact on the decrease
 in PANSS Scores.
\end_layout

\begin_layout Part
Patient Segmentation
\end_layout

\begin_layout Standard
For this problem I used two forms of clustering.
 One being k means clustering, and the other being hierarchical clustering
 so I could see a dendogram.
 For K means clustering, I began by clustering on various components that
 made up the PANSS score.
 For example I tried P1 with N1, P1 with G1 etc.
 I choose 3 centroids.
 I also used cross validation to choose the best k.
 In the scatter plot below, it shows the locations of the centorids of the
 clusters when clustering using P1 and N1.
 The centroids are in orange.
 The blue dots are the xvalue combinations with P1 and N1.
 
\end_layout

\begin_layout Standard
\noindent
\align center
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename img/realclustering_1.png
	lyxscale 50
	width 85page%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
K Means Clustering
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
I then wanted to know what a dendogram of this would look like, so one was
 constructed.
 There where two clusters.
 One thing I found quite interesting is that one of the clusters (green
 is N1) is larger than the other cluster.
 I thought that the clusters would be of similar size.
 Also the clusters don't meet for a while.
 
\end_layout

\begin_layout Standard
\noindent
\align center
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename img/dendogram.png
	lyxscale 50
	width 85page%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Dendogram
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Part
Forecasting
\end_layout

\begin_layout Paragraph*
Kaggle Reference
\end_layout

\begin_layout Standard
Team Name: Adam Kainikara.
\end_layout

\begin_layout Standard
Work done by Adam Kainikara.
\end_layout

\begin_layout Standard
There were many data wrangling steps involved in this part of the project.
 I used data from set E for this part.
 At first, I created a structured array which was organized by study, country,
 txgroup, assesment id, patient id, visit day, xvalues, panss score and
 lead status.
 Then I made a function that found every unique patient id.
 This was to figure out how many patients were in the study.
 After collecting every patient id, I created a blank dictionary.
 The dictionary would have the patient id as the key.
 For values, I stored all the associated values of each patient in an array.
 These associated values include: PANSS score, country, etc.
 For patients that had one or more visit days, the information would also
 be stored in arrays.
 It is stored in the same way as seen in section 1.
 Patients who did not have at least two visit days where removed from the
 study.
 In a spread sheet, I did some basic calculations.
 These calculations included figuring out the average % change for each
 patient from the initial reading in the study to the last reading in the
 study.
 
\end_layout

\begin_layout Standard
For my first prediction, I uploaded a CSV that contained the most recent
 visit day's PANSS score.
 I did this to see if the most recent visit PANSS score would be similar
 to the real 18th week score.
 This resulted in a score of 6.61736.
 
\end_layout

\begin_layout Standard
My next submission was the score decreased by the average decrease calculated
 in the spread sheet.
 To do this, I calculated each patients change in PANSS score from the first
 week to the last week.
 I found the average % drop across the data set.
 I then changed the initial reading (first day's reading) by the average
 % change.The average % change across the data set was about 10%.
 This did not change my score significantly.
 
\end_layout

\begin_layout Standard
For my final few submissions I created a function that did linear interpolation
 where:
\end_layout

\begin_layout Standard
\begin_inset Formula $\alpha=\frac{y_{2}-y_{1}}{x_{2}-x_{1}}\,$
\end_inset

 and 
\end_layout

\begin_layout Standard
\begin_inset Formula $\hat{y}=(1-\alpha)y_{1}+\alpha y_{2}$
\end_inset


\end_layout

\begin_layout Standard
The linear interpolation resulted in better results.
 My best score was 6.5099.
 In my created function, I tried several variations.
 The first variation I did was predict the average PANSS score if a patient
 did not get to day 129.5.
 I used day 129.5 as it is 18.5 weeks.
 In my spreadsheet I calculated that the average visit day turns into about
 17.6 weeks.
 Although day 126 (18 weeks) does not necessarily mean that that was the
 patient's 18th week, I assumed that most patients would be around this
 time period.
 This assumption was made because the average patient stayed for 17.6 weeks.
\end_layout

\begin_layout Standard
Another variation I did if a patient did not make it to day 129.5 was to
 calculate the slope between the last two points, fit a line, and predict
 what the score for day 129.5 would have been.
 
\end_layout

\begin_layout Standard
The last attempt I did involved extrapolation.
 When I used extrapolation though, my score got worse (7.74936) so I did
 not use extrapolation.
 In the end using linear interpolation with the day as 129.5 days produced
 the best results for me.
 The code for this section is the function(s) desired_data in the interpol3.py
 file.
\end_layout

\begin_layout Part
4 Binary Classification
\end_layout

\begin_layout Part*
Kaggle Reference
\end_layout

\begin_layout Standard
Team Name: Adam Kainikara.
\end_layout

\begin_layout Standard
Work done by Adam Kainikara.
\end_layout

\begin_layout Standard
There were many data wrangling steps involved in this part of the project.
 I used data sets A,B,C,D for training and E as the test set.
 At first, I created a structured array which was organized by study, country,
 txgroup, assesment id, patient id, visit day, xvalues, panss score and
 lead status.
 Then made a function that found every unique patient id.
 This was to figure out how many patients were in the study.
 After collecting every patient id, I created a blank dictionary.
 The dictionary would have the patient id as the key.
 For values, I stored all the associated values of each patient in an array.
 For patients that had one or more visit days, the information would also
 be stored.
 Patients who did not have at least two visit days where removed from the
 study.
 
\end_layout

\begin_layout Standard
For classification I used many classification methods.
 These include knn, naive bayes, decision trees, random forests and support
 vector machines.
 When using knn, I choose many different K values, however my accuracy was
 never very good so I decided not to use it.
 My score on kaggle was 16.
 The others (naive bayes, decision trees, random forests) produced poor
 training accuracy.
 
\end_layout

\begin_layout Standard
My best scores occurred while using a support vector machine.
 The support vector machine gave me a score of 0.858 with a training accuracy
 of 0.812.
\end_layout

\begin_layout Standard
To see if I could improve my score, I tried using different kernels such
 as linear or sigmoid however these did not improve my score.
 I did add a regularization parameter of 0.95.
 This changed my score to 0.854
\end_layout

\begin_layout Standard

\end_layout

\end_body
\end_document
